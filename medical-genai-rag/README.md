# Medical GenAI RAG System

> A production-style Retrieval-Augmented Generation system for medical queries, built with PyTorch, HuggingFace Transformers, FAISS, and FastAPI.

âš ï¸ **DISCLAIMER**: This system is for **educational and research purposes only**. It does NOT provide medical advice. Always consult a qualified healthcare professional.

---

## ğŸ—ï¸ Architecture

```
Client (API Request)
      â†“
  FastAPI Server
      â†“
Orchestration Pipeline
  â”œâ”€â”€ Document Ingestion (PDF/TXT â†’ chunks)
  â”œâ”€â”€ Embedding (Sentence Transformers â†’ FAISS)
  â”œâ”€â”€ Retriever (FAISS similarity search)
  â”œâ”€â”€ Prompt Builder (context injection)
  â””â”€â”€ Generator (Fine-tuned LLM via LoRA/QLoRA)
      â†“
  JSON Response
```

## ğŸ“ Project Structure

```
medical-genai-rag/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Input medical documents (PDFs, TXT)
â”‚   â””â”€â”€ processed/        # Chunked data, FAISS index, training data
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ loader.py          # Document loading (PDF, TXT, MD)
â”‚   â””â”€â”€ chunker.py         # Text chunking with overlap
â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ embedder.py        # Sentence Transformer embeddings
â”‚   â””â”€â”€ vector_store.py    # FAISS vector storage & search
â”œâ”€â”€ finetuning/
â”‚   â””â”€â”€ lora_train.py      # LoRA/QLoRA fine-tuning pipeline
â”œâ”€â”€ inference/
â”‚   â””â”€â”€ model_loader.py    # Model loading & text generation
â”œâ”€â”€ orchestration/
â”‚   â””â”€â”€ pipeline.py        # Central RAG pipeline orchestrator
â”œâ”€â”€ api/
â”‚   â””â”€â”€ app.py             # FastAPI REST API
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh           # Environment setup script
â”‚   â””â”€â”€ run_training.sh    # Fine-tuning launch script
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md    # Detailed architecture docs
â”‚   â””â”€â”€ learning_notes.md  # Learning notes & explanations
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone and setup
cd ~/medical-genai-rag
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 2. Add Medical Documents

Place PDF/TXT files in `data/raw/`:
```bash
cp your_medical_docs.pdf data/raw/
```

### 3. Build Index

```bash
python -c "
from orchestration.pipeline import RAGPipeline
pipeline = RAGPipeline()
pipeline.build_index()
"
```

### 4. Run Fine-Tuning (GPU required)

```bash
python finetuning/lora_train.py --base-model mistralai/Mistral-7B-Instruct-v0.2
```

### 5. Start API Server

```bash
python -m api.app
# API available at http://localhost:8000
# Docs at http://localhost:8000/docs
```

### 6. Query the System

```bash
curl -X POST http://localhost:8000/ask \
  -H "Content-Type: application/json" \
  -d '{"question": "What are the symptoms of diabetes?"}'
```

## ğŸ§  Tech Stack

| Component | Technology |
|-----------|-----------|
| Language | Python 3.10+ |
| ML Framework | PyTorch |
| LLM | HuggingFace Transformers |
| Fine-tuning | PEFT (LoRA/QLoRA) + TRL |
| Quantization | BitsAndBytes (4-bit NF4) |
| Embeddings | Sentence Transformers |
| Vector Store | FAISS |
| API | FastAPI + Uvicorn |
| GPU | NVIDIA L40S |

## ğŸ”§ Key Concepts

### RAG (Retrieval-Augmented Generation)
Instead of relying solely on the LLM's training data, RAG retrieves relevant documents and injects them as context into the prompt. This grounds the response in actual data and reduces hallucination.

### LoRA (Low-Rank Adaptation)
Instead of fine-tuning all billions of parameters, LoRA adds small trainable adapter matrices to specific layers. This reduces memory usage by 10-100x while maintaining most of the performance.

### QLoRA (Quantized LoRA)
Combines 4-bit quantization of the base model with LoRA adapters trained in float16. This enables fine-tuning 7B+ parameter models on a single GPU.

## ğŸ“Š API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | API info |
| GET | `/health` | Health check |
| POST | `/ask` | Ask a medical question (RAG) |
| POST | `/index` | Build/rebuild FAISS index |
| POST | `/retrieve` | Retrieve chunks (debug) |

## ğŸ“ License

MIT License - For educational and research purposes.

## ğŸ‘¤ Author

Victor - GenAI Intern Project
